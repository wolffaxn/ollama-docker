DOCS_PATH=assets

CHUNK_SIZE=1000
CHUNK_OVERLAP=100

#EMBEDDING_MODEL=bge-m3:567m
EMBEDDING_MODEL=jina/jina-embeddings-v2-base-de:latest
#EMBEDDING_MODEL=mxbai-embed-large:335m
#EMBEDDING_MODEL=nomic-embed-text:v1.5

ENABLE_HYBRID=False

# local ollama server on macos (installed via homebrew)
OLLAMA_BASE_URL=http://localhost:11434
# local ollama server as docker container
#OLLAMA_BASE_URL=http://localhost:7869
OLLAMA_MODEL=llama3.2:3b
#OLLAMA_MODEL=llama3.1:8b
#OLLAMA_MODEL=gemma2:9b

OPEN_API_BASE_URL=https://api.openai.com
#OPEN_API_KEY=
#OPEN_API_VERSION=

QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION_NAME=documents

REDIS_URL=redis://localhost:6379
REDIS_COLLECTION_NAME=documents

REQUEST_TIMEOUT=120

# Ollama
VECTOR_LENGTH=768
# OpenAI
#VECTOR_LENGTH=1536
